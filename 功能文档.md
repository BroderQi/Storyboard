# Storyboard 核心功能规格文档（纯功能版）
avalonia +内置数据库 SQLite + EF Core +C# 实现整个客户端功能
---

## 1. 项目与数据对象

### 1.1 项目（Project）

系统必须支持：

* 创建项目
* 打开项目
* 项目内数据持久化

项目包含：

* 原始视频（可选）
* 分镜数据（Shot 列表）
* 生成的图片资源
* 生成的视频资源

---

## 2. 视频导入功能

系统必须支持：

* 导入本地视频文件
* ffmpeg解析并保存以下元数据：

  * 视频时长
  * 分辨率
  * 帧率

---

## 3. 抽帧功能

### 3.1 抽帧模式

系统必须支持以下抽帧模式：

1. **定数抽帧**

   * 输入：目标帧数 N
   * 行为：在视频全时长内均匀抽取 N 帧

2. **动态间隔抽帧**

   * 输入：目标帧数 N
   * 行为：根据 视频时长 / N 自动计算时间间隔并抽帧

3. **等时抽帧**

   * 输入：固定时间间隔（毫秒）
   * 约束：最多抽取 100 帧

4. **关键帧抽取**

   * 基于画面变化自动检测
   * 无需用户输入参数（高级参数可选）

---

## 4. 分镜（Shot）数据结构

系统必须以 **分镜（Shot）** 作为最小工作单元。

### 4.1 Shot 字段（固定）

* 镜头号（自动生成）
* 时长
* 原视频片段（起止时间）
* 镜头类型
* 核心画面
* 动作指令
* 场景设定
* 首帧提示词
* 尾帧提示词
* 首帧图（资源引用）
* 尾帧图（资源引用）
* 成品视频（资源引用）

### 4.2 Shot 基本能力

系统必须支持：

* 新增 Shot
* 删除 Shot
* 复制 Shot
* 调整 Shot 顺序

---

## 5. 分镜初始化规则

系统必须支持以下方式生成 Shot 初始数据：

1. 基于抽帧结果自动生成 Shot

   * 自动计算镜头时长
   * 自动生成原视频片段区间

2. 基于文本生成 Shot（见第 10 章）

---

## 6. AI 镜头解析功能（图 → 文本）

### 6.1 功能目标

将首帧图 / 尾帧图解析为结构化分镜描述。

### 6.2 输入条件

* 首帧图（必需）
* 尾帧图（可选）

### 6.3 AI 输出字段

AI 必须返回以下字段：

* 镜头类型
* 核心画面
* 动作指令
* 场景设定
* 首帧提示词
* 尾帧提示词

### 6.4 数据写入规则

* AI 输出必须写入对应 Shot 字段
* 若字段已有内容，必须提供：

  * 覆盖
  * 追加
  * 放弃

---

## 7. AI 图片生成功能

### 7.1 生成对象

* 首帧图
* 尾帧图

### 7.2 输入来源

* Shot 中的提示词与描述字段

### 7.3 多次生成规则（强制）

* 每一次生成的图片必须被保存为独立资源
* 多次生成不得自动覆盖 Shot 中已绑定的图片

### 7.4 绑定规则

* 只有当用户明确选择某张图片时
* 该图片才可被绑定为：

  * 首帧图 或 尾帧图

---

## 8. AI 视频生成功能

### 8.1 生成条件

* Shot 必须已绑定：

  * 首帧图
  * 尾帧图

### 8.2 输入来源

* 首帧图
* 尾帧图
* 动作指令
* 场景设定
* 镜头时长

### 8.3 多次生成规则（强制）

* 每次生成的视频必须保存为独立资源
* 不得自动覆盖已绑定的成品视频

### 8.4 成品绑定

* 仅当用户明确选择某个视频资源时
* 该视频才被绑定为 Shot 的成品视频

---

## 9. 批量处理能力

系统必须支持：

* 对多个 Shot 批量执行：

  * 镜头解析
  * 图片生成
  * 视频生成

批量任务中：

* 单个 Shot 失败不得影响其他 Shot

---

## 10. 文本 → 分镜功能

### 10.1 输入

* 用户输入自然语言描述

### 10.2 AI 输出

AI 必须生成：

* 多个 Shot
* 每个 Shot 包含：

  * 镜头号
  * 时长
  * 镜头类型
  * 核心画面
  * 动作指令
  * 场景设定
  * 首帧提示词
  * 尾帧提示词

---

## 11. 任务与执行控制

系统必须具备：

* 异步任务执行能力
* 任务状态：等待 / 执行中 / 成功 / 失败
* 支持：

  * 取消任务
  * 重试失败任务

嵌入到生成图片/视频的位置，是不是用户体验更好？
---

## 12. AI 模型与 Provider 管理

系统必须支持：

* 多 AI Provider 接入
* Provider 分类：

  * 文本理解
  * 图片生成
  * 视频生成

### 12.1 Provider 能力声明

每个 Provider 必须声明：

* 支持的能力类型
* 输入限制
* 输出格式

### 12.2 外部 API 文档与模型列表（参考）

以下为常见 Provider 的官方或常用 API 文档入口；可用模型以各家模型列表为准。

* DeepSeek（文本理解）：https://api-docs.deepseek.com/zh-cn/
* 通义千问（文本理解/图片生成/视频生成）：https://help.aliyun.com/zh/model-studio/first-api-call-to-qwen#43aac16745tit
* 火山引擎（文本理解/图片生成/视频生成）：https://www.volcengine.com/docs/82379/1399008?lang=zh
* OpenAI（文本理解/图片生成/视频生成 Sora2）：https://platform.openai.com/docs
* Gemini / Veo / Nano Banana（文本理解/图片生成/视频生成）：https://ai.google.dev/gemini-api/docs?hl=zh-cn
* Stability AI（官方 Stable Diffusion）：https://platform.stability.ai/docs/api-reference
* Stable Diffusion（文本理解/图片生成/视频生成）：https://stablediffusionapi.com/docs/stable-diffusion-api/overview（第三方服务，非官方）

### 12.3 Key/模型配置约定

* 文本理解统一通过 Semantic Kernel 进行编排，不自带模型与密钥。
* 用户需在设置中自行配置 API Key、Endpoint 与模型名称。

---

## 13. 功能边界（本期不做）

当前阶段不包含：

* TTS 配音
* 自动剪辑优化
* 自动风格迁移
* 社交发布
